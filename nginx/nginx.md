##### nginx, 带负载均衡功能的端口映射?

>   ​	所谓的工作在应用层, 就是nginx服务拿到请求, 然后再次打包成ip数据包, 分配给其他服务器

###### 反向代理

​	就是带负载均衡的端口映射呗

​	实现跨域: nginx和服务器在一个子网, 哪怕服务器上的服务设置了限制跨域, 因为来请求的是同一个子网下的nginx服务器, 那么直接就能请求, 也就实现了跨域访问.

###### 静态服务器

​	事先配置好哪些请求是在请求静态资源, 直接就读取静态资源返回, 其他的就通过负载均衡发给其他服务器来处理

###### 性能瓶颈?

​	跟lvs一个道理, 请求包和响应包都经过nginx服务器, 这个带宽就决定了后面服务器数量的上限, 因此应当水平扩展nginx的数量

​	水平扩展nginx数量后, 在nginx集群前面使用 keepalive 服务器, 用户访问 keepalive 服务器, 得到一个可用的 nginx 服务地址, 然后再去访问

​	为什么整这么复杂? 直接keepalive后面接真实服务器不就完了? 

​	keepalive是做状态检测的, 只有检查活跃服务器的功能, 没有负载均衡的功能, 要是能把 keepalive和nginx做在一起, 架构也就不用这么麻烦了

###### 热部署?

​	更新配置文件后直接reload就能直接更新, 不需要重启服务

​	其实就是reload时新建几个进程读取新的配置, 然后杀掉旧进程

###### 高并发?

​	单机最多支持5w并发访问

​	实现使用的是epoll系统调用, 能在不阻塞的情况下处理大量请求, 而且性能友好





###### 为什么lvs+nginx?

​	lvs是能做分发, 但是通常情况下都是使用DR模式, 也就是只管把请求发出去, 然后由服务器自己返回响应, 如果服务器恰好出了问题, 那么lvs这边是不知道的, 也就是说, 这次请求会直接失败

​	但是nginx是包揽接收请求和返回响应一条龙服务, 如果后面的服务器出了问题, 可以立即再给其他服务器发请求过去, 直到收到响应, 也就是说, 只要后面的服务器不全完蛋, 那么承包给nginx的请求总是可以得到正常的响应

​	所以, 把lvs收到的请求分给nginx服务, nginx就能把这个请求负责到位, 就能提高架构的高可用能力

​	那直接用nginx不就完事了?

​	因为nginx请求和响应通吃, 带宽限制, 这注定了后面接不了几台服务器, 所以还得用lvs对nginx集群进行扩展
