

#### 处理器的两种状态

​	处理器根据当前状态判断是否可以执行特权指令, 处理器的状态根据***程序状态寄存器***中存储的值来标识

* 用户态(目态) : 用户态下只能执行非特权指令
* 内核态(管态) : 内核态下可以执行特权指令和非特权指令



指令 : cpu直接执行的命令

* 特权指令 : 涉及敏感操作的指令 , 例如清除内存中的值

* 非特权指令 : 就是普通的指令, 例如创建变量, 加减乘除



应用程序

* 内核程序 : 可以执行特权程序的程序, 运行在内核态

* 用户程序 : 只能执行非特权指令的程序, 运行在用户态







#### 操作系统内核

​	操作系统中提供基本的管理硬件的功能部分, 称为内核. 其他的附加在操作系统中的功能就不属于内核, 比如操作系统的任务管理器, 计算器,

* 大内核 : 将从操作系统主要功能模块都作为系统内核, 这些程序都运行在核心态
  * 优点: 这些程序都运行在核心态, 无需频繁切换处理器状态, 因此运行效率高
  * 缺点: 系统不够精简, 内部代码量大, 难以维护
* 微内核 : 仅将必要的功能作为系统内核, 所以仅有这些最主要的程序运行在核心态
  * 优点 : 内核功能少, 维护方便
  * 缺点: 需要频繁切换处理器状态, 性能低





#### 中断

​	中断由计时器触发, 每跑完一个处理器时间片, 就发出一次中断, 因为中断的存在, 才能实现多个程序的并发执行

所以多个程序并发执行时流程如下:

cpu跑程序1(用户态) > 中断 > cpu转内核态 > 操作系统任务调度程序设置下一个运行的程序 > cpu转用户态 > cpu运行程序2 > 中断 > ......

中断分类

* 内中断 : 程序主动触发中断, 可能的原因有 
  * 发生异常
  * 请求系统调用, 也就是需要执行核心态才能完成的操作, 但是程序又运行在用户态没权限, 那怎么办呢, 就只能主动中断, 向操作系统发起请求, 让操作系统在核心态下代替执行特权操作, 例如调用其他硬件, 请求分配内存
  * 硬件故障
* 外中断 : 来自cpu外部的原因导致的中断, 可能的原因有
  * I/O操作完成, 发出中断信号, 就是喊, 我搞完了
  * 用户强制终止进程





#### 系统调用

​	系统调用(程序接口) , 就是操作系统提供给应用程序用来使用共享资源例如硬件资源的接口, 这些共享的资源不应当被应用程序任意的使用, 否则容易造成混乱和崩溃, 因此由操作系统对资源进行统一管理, 应用程序只能通过系统调用的接口告诉操作系统要使用哪些资源.

​	高级操作语言中提供的库函数就是对系统调用接口的封装, 屏蔽了不同操作系统中系统调用接口的差异, 同时也封装了系统调用的细节, 使其更加容易使用





#### 进程

​	首先说程序其实就是一段程序代码 

​	PCB :  进程控制块, 保存进程的各种信息, 如进程号, 用户号, 程序段内存地址, 数据段内存地址等

​	一个进程包含三个部分: PCB, 程序段, 数据段

​	在执行程序的时候, 操作系统会为其创建一个 PCB保存到内存中, 以及分配一段内存用来存放程序段和数据段

​	操作系统的进程调度其实就是在不同的 PCB之间切换执行

###### 进程的状态

* 运行态 : 正在占用cpu
* 就绪态 : 达到运行条件, 但是苦于没有cpu资源
* 阻塞态 : 因为等待其他的事件而不能执行, 比如等 io 操作的完成
* 创建态 : 进程刚刚发出创建请求, 操作系统正在为其分配 PCB, 内存等资源
* 终止态 : 进程已经停止运行, 操作系统正在回收分配给它的资源, 删除PCB

###### 进程通信的三种方式

* 共享内存 : 直接在内存中给两个要通信的进程分配一段内存
* 管道通信 : 其实也是在内存中开一段内存称之为管道, 通信方式是半双工, 一方读, 一方写
* 消息传递 : 直接通过原语程序将消息发送到接收方的消息队列中, 然后接收方使用接收原语程序读取消息



#### 线程

​	一个进程中可以包含多个线程, 这些线程之间可以并发执行, 例如QQ进程中, 包含视频聊天, 发送文件的线程, 那么就可以视频聊天的同时进行文件传输

​	在线程出现之前, 进程是cpu的最小执行单位, 一个进程就对应着一份代码, 而在线程出现之后, 线程是cpu的最小执行单位, 一个进程中包含多个线程的意思就是一个进程包含多段代码, 这些代码被并发执行.

​	线程是cpu执行的最小单位, 进程是资源分配的最小单位, 操作系统每次是将资源分配给进程, 这样这个进程下的所有线程都可以使用这些资源

​	线程相较于进程, 进一步提高了并发度, 同时线程之间的切换开销远小于进程之间的切换, 这就提高了资源的利用率

​	多cpu的计算机中, 同一个进程下的不同线程可以同时占用多个cpu, 因为操作系统视线程为调度单位.

​	每一个线程也对应着 TCB 线程控制块

​	线程也三种状态 : 运行, 就绪, 阻塞

##### 线程的类型

> goroutine 是在内核级别线程上创建多个用户级别线程, 同时动态调整每一个 goroutine 分配到的栈大小, 所以能够同时创建极多的 goroutine

* 用户级线程

  线程在应用程序中由用户自己定义, 线程的管理和调度也由用户自己实现, 在操作系统的角度看, 只是在为一个进程分配资源, 所以这些线程运行在用户态下
  
* 内核级线程

  线程是操作系统级别的线程, 在操作系统的角度下, 是在为多个线程分配资源, 因此这种运行在内核态, 线程的切换和调度只能通过请求操作系统来完成

##### 多线程模型

* 多对一 , 多个用户级线程对应一个内核级线程, 本质上还是一个线程在被操作系统调度, 并不能分配到更多的时间片, 并不能提高并发
* 一对一 , 一个用户级线程对应一个内核级线程, 多个线程能够公平地被调度, 能够分到更多的事件片, 能够提高并发, 但是内核级线程总数是有上限的, 而且内核级线程分配的最小内存大小是固定的, 那么就不可避免造成内存的浪费, 同时切换线程的操作需要切换到内核态, 浪费性能, java的多线程是这种模型
* 多对多, 多个用户级别对应多个内核级别, 既能够提高并发, 又能够避免内存浪费, 又能够避免内核态切换浪费时间, golang的多线程模型是这种



#### 内存

​	用来衔接硬盘和处理器的硬件, 弥补了硬盘传输速度慢与处理器处理速度快之间的速度不匹配问题

​	每个程序运行后都会分配到一段内存, 其中包括 PCB, 程序段, 数据段, 处理器每次从程序段中读取程序, 从数据段中读取数据来运行程序.

##### 为什么32位系统最多只支持4G内存?

​	操作系统根据内存地址去对应的位置取数据, 32位系统使用32个二进制位存储数据内存地址, 而32位二进制位最多表示4G的地址.

​	如果把给数据分配地址看作是在大楼中分配门牌号, 那么就相当于手里只有4G的门牌号, 哪怕是总容量是8G的大楼, 那么后面4G也分配不到门牌号, 也就是说后面4G的内容会因为没有门牌号而无法访问.

##### 用户空间和内核空间

​	首先, 内核程序运行需要使用内存, 用户程序运行也需要使用内存, 那么为了保护内核程序的安全性, 如何防止用户程序操作内核程序使用的数据呢? 

​	操作系统将内存划分为用户空间和内核空间, 最简便的方法就是直接在内存中间切一刀, 低于这个地址的部分给内核程序使用, 高于这个地址的部分给用户程序使用, 这样在检查用户程序是否要操作内核程序数据时就变得很简单, 只要判断其访问的数据地址是否在内核空间里即可.

​	具体的, 在linux中, 如果内存大小为4G, 那么前1G将被分配为内核空间, 后3G将会分配为用户空间.

##### 内存的地址转换

​	应用程序使用高级语言, 在交给处理器执行之前都要先经过编译为处理器能够识别的指令, 同时需要指定使用到的数据的地址, 这里的地址使用的都是逻辑地址, 即数据相对于数据段第一个位置的偏移量, 在运行的时候根据数据段第一个位置和偏移量转换为实际地址, 然后去该地址取值.

##### 内存的空间扩充

* 覆盖技术 : 如果程序本身都比内存大, 那么肯定不能全部加载到内存. 覆盖技术是指在程序有明确的层次结构时, 根据程序的层次调用情况, 根据每层模块可能使用的最大内存来分配内存, 这样就能减小内存的使用量 , 但是这种层次结构需要程序员手动定义, 十分麻烦, 现在已经被淘汰
* 交换技术 : 将硬盘分为文件区和交换区, 文件区使用离散存储的方式为了提高磁盘利用率, 交换区采用连续的存储方式为了提高io速度, 在内存吃紧的情况下, 将内存中的一些程序数据暂时移动到硬盘的交换区, 待到内存宽松时再读取回来.

##### 内存的存储保护

​	内存中操作系统和每个程序都分配到独立的空间, 应当保证某个程序不能操作其他程序的内存, 否则会造成极大的危险, 所以需要对内存进行隔离分段保护.

​	可以在寄存器中保存当前程序内存的上下限地址, 处理器在运行指令时先检查是否符合上下限规范, 不符合则拒绝操作.

​	也可以在寄存器中保存当前程序内存的起始地址和内存段总长度, 然后处理方法同上.

##### 内存分配与回收

###### 连续的内存分配

* 单一内存分配 : 淘汰

  <img src="./操作系统.assets/1620654540008.png" alt="1620654540008" style="zoom: 67%;" />
  
* 固定分区分配 : 淘汰

  <img src="./操作系统.assets/1620654720264.png" alt="1620654720264" style="zoom:67%;" />

  那么操作系统怎么知道哪些分区有没有被分配呢?

  <img src="./操作系统.assets/1620654846378.png" alt="1620654846378" style="zoom:67%;" />

* 动态分区分配

  <img src="./操作系统.assets/1620654994807.png" alt="1620654994807" style="zoom:67%;" />

  那么采用什么样的数据结构来存储分区分配状态呢?

  <img src="./操作系统.assets/1620655093933.png" alt="1620655093933" style="zoom:67%;" />

  

###### 离散的内存分配

* 分页离散分配

  <img src="./操作系统.assets/1620657907364.png" alt="1620657907364" style="zoom:67%;" />

  将内存分为多个大小相同的内存段, 称为 页框

  将应用程序需要的在内存中存储的数据分为与 页框 大小相同的数据段, 称为 页面

  将页面放到页框中, 形成一一对应的关系, 这样就实现了数据的离散存储

  * 基本地址变换机构

  ​	将所有程序的页面起始位置和页面长度以表的形式保存到内存中, 称为页表 . 要访问某个页面时, 首先去页表查询页面所在位置, 然后再去访问该位置.

  * 具有快表的地址变换机构

  ​	使用一个寄存器作为页表的缓存, 首先去寄存器中查询页面位置信息, 如果有则直接返回, 没有则去页表查询. 这个寄存器的作用就相当于 redis 缓存机制.

  * 使用两级页表的变换机构

    	1. 如果程序占用很多个页面, 那么它的页表也会相应的很大, 而页表又需要连续存储, 这就使得页表在内存中占用很多连续的页框, 使得离散分页机制失去了作用.
    	2. 其实没有必要让整个页表都常驻内存, 因为往往只有少部分页面会被频繁访问

    所以可以将页表拆分为多个小页表, 然后为它们建立目录, 称为二级页表, 那么查询时, 首先查询二级页表, 然后查询页表, 然后查询数据.

* 基本分段存储管理

  分段存储类似于分页存储, 不同的是分出来的段长度不同, 且这些段根据程序员从逻辑上的进行定义
  
  分段存储同样需要类似于分页技术中页表的目录, 称为段表, 用来记录各个段所在位置和长度, 查询时首先查询段表, 然后去对应位置访问分段.
  
  ![1620711770432](./操作系统.assets/1620711770432.png)
  
* 段页式管理

  ​	仅仅页表式管理能够对内存有效的利用, 但是不利于程序按照逻辑分模块的共享数据

  ​	仅仅段表式管理能够方便地实现程序按照逻辑分模块的共享数据, 但是因为分段的大小是不固定的, 动态分配的, 所以可能产生较多的外部碎片, 降低内存的利用率.

  ​	段页式管理首先使用段表式将程序按照逻辑模块分别存储, 然后再每一个分段中, 又按照进行分页存储, 这样就可以同时利用两种管理方式的优点. 所以段页式管理中一个程序对应一个段表, 然后每个分段对应一个页表.



#### 高速缓存

​	<img src="./操作系统.assets/1620714858445.png" alt="1620714858445" style="zoom:67%;" />

​	内存的读写速度和cpu的处理速度存在数量级的差异, 在内存和cpu之间添加读写更高速的高速缓存可以在一定程度上弥补这种差异, 这里的高速缓存机制就类似于 redis.

​	那么将哪些数据存到高速缓存中比较好呢 ? 可以将内存中频繁访问的数据保存到更快速的存储设备中, 这样就可以提高程序的运行速度.

​	那么寄存器和高速缓存的区别在哪里呢 ? 

​	寄存器是cpu执行指令时直接用到的内存单元, 相当于工作台, 其大小只需要足够执行一句指令即可.

​	高速缓存是对内存读写速度不足的进一步弥补, 一次取一批数据放到高速缓存中供cpu使用.

​	两者都集成在cpu中, 高速缓存分为 L1/L2/L3 三种, L1/L2是cpu独享缓存, L3是多cpu共享缓存.





#### 虚拟内存

​	程序运行时, 只将必要部分装入内存, 其余部分暂时存储到外存, 然后随用随取

​	如果内存不够, 也会将内存中的数据暂时移动到外存, 待到内存充足时再移动回内存.

​	这里将程序暂时存到外存的技术就是虚拟内存技术.

缺页

​	因为虚拟内存机制的存在, 所以可能造成要用到的数据当时没在内存中, 那么会产生缺页中断, 此时需要操作系统介入, 将请求的页面加载到内存中, 如果此时内存又是满的, 那么操作系统需要决定把哪个页面换出去.

​	那么如何知道当前请求的页面是否在内存中呢 ? 这个信息被作为字段存储到页表中, 同时需要记录该页在外存中的地址.



#### 文件管理

​	操作系统将文件分段存储到多个磁盘块中, 磁盘块是磁盘的基本存储单位, 每次 IO操作只能读取一个磁盘块, 因此将数据尽量存储到更少的磁盘块中能够减少 IO的次数, 从而提高性能.

FCB

​	操作系统对每个文件夹都保存一个文件控制块(FCB) , 用来保存当前文件夹下所有文件对应的磁盘块的位置 以及 各个文件的详细属性信息.

带索引的FCB

​	FCB中保存了每个文件的所有属性信息, 占用空间较大, 每个磁盘块能够存放的 FCB就比较少, 在对文件进行检索时, 需要读取多个磁盘块进行多次IO操作, 这就不利于性能. 

​	此时, 可以建立文件索引信息表, 仅存放文件名和其对应的 FCB所在的位置, 这个索引表就很小, 一个磁盘块中就可以存放更多的索引, 在进行检索时, 只需要进行少量的IO就可以找到目标文件的索引, 然后根据索引取得FCB, 最后获取其在磁盘上的位置, 这样就可以大幅提高检索性能.

​	这种索引就相当于B+树的道理.



文件分配方式

​	文件被分成段在磁盘块上存储, 这里涉及几种存放方式

* 连续分配 : 一个文件分配到连续的磁盘块上

  * 优点 : 

    因为读取磁盘块需要移动磁头到该位置, 连续的存储时磁头需要移动的位置短, 所需时间短

    连续的存放方式支持随机访问(直接访问), 也就是直接定位到文件的某个位置

  * 缺点 : 

    会造成大量磁盘碎片

    文件在扩展时需要整体迁移, 及其消耗性能

* 链接分配 : 离散的存储文件在多个磁盘块, 磁盘块每一块上存储下一块的地址或者直接把所有的文件占用磁盘块信息都统一存储到一个表中

  * 优点 : 文件容易扩展
  * 缺点 : 只能连续访问, 不能随机访问, 如果是统一存储到一个表中的话, 支持随机访问



存储空间的划分

​	操作系统会将物理磁盘分为多个逻辑分区, 每个逻辑分区又分为目录区和文件区, 目录区用于存放该分区中的FCB和存储空间管理信息

<img src="./操作系统.assets/1620722685232.png" alt="1620722685232" style="zoom:50%;" />



文件操作 

* 打开文件 

  1. 操作系统首先根据给定的目录找到对应的目录表

  2. 然后从中找到文件信息, 其中包括文件的各项属性, 在磁盘中的位置, 用户权限等所有信息

  3. 根据发起操作的用户从文件信息中查看是否具有打开权限, 没有则拒绝操作

  4. 将文件信息其加载到内存的 ***打开文件表*** 中, 之后使用内存中打开文件表的记录来指明要操作的文件

     * 打开文件表 : 分为系统打开文件表和用户进程打开文件表, 系统的存储所有被打开的文件以及被多少个用户进程打开, 用户进程打开文件表只存放当前进程打开的文件. 因为系统的表有计数功能, 所以可以以此实现"文件被占用"等功能.

       <img src="./操作系统.assets/1620726411402.png" alt="1620726411402" style="zoom:67%;" />

* 关闭文件

  1. 从打开文件表中删除该文件信息记录
  2. 从内存中清除分配给该文件的部分

* 读文件

  1. 打开文件, 即将查询到的文件信息保存到打开文件表中
  2. 指明读入多少个数据到内存的哪里

* 写文件

  1. 打开文件, 即将查询到的文件信息保存到打开文件表中
  2. 指定从内存中哪一块取多大的数据, 并指明要写回到外存中的什么位置





#### 磁盘

![1620738842560](./操作系统.assets/1620738842560.png)

![1620739063416](./操作系统.assets/1620739063416.png)

![1620739086502](./操作系统.assets/1620739086502.png)

![1620739132095](./操作系统.assets/1620739132095.png)

![1620739153849](./操作系统.assets/1620739153849.png)





#### IO模型

​	大多数操作系统使用的是 ***缓存IO机制*** , 也就是先将文件内容读取到内存中内核空间部分, 然后再从内核空间读取到用户空间

​	那么为什么需要先将文件读取到内核空间?

​	因为IO操作属于特权指令, 只能由内核程序来执行, 所以用户程序在执行IO操作时, 总是需要call系统调用, 然后由内核程序完成指定的IO操作, 因此理所当然的做法是, 内核程序先将文件数据都读取到自己的内存空间下, 然后再一次性地将数据发送到用户空间中.

###### 五种IO机制

*   阻塞IO

    ​	用户程序从开始发起系统调用直到收到IO操作结束的消息之前, 都处于阻塞态不占用cpu资源

    ![image-20210701160534517](操作系统.assets/image-20210701160534517.png)

*   非阻塞IO

    ​	用户程序发起系统调用后, 内核程序开始IO操作, 如果还没有操作完成, 那么直接给用户程序返回error, 用户程序收到消息一看是error, 那么就知道了还没读完, 然后用户程序就不断轮询发送系统调用, 直到内核程序完成了IO操作, 此时返回ok

    ​	这种方式用户程序全程不闲着, 一直问, 好了吗好了吗

    ![image-20210701160917927](操作系统.assets/image-20210701160917927.png)

*   IO多路复用

    ​	如果同时来了10个IO请求

    ​	阻塞IO,  如果只有一个进程一个线程, 那就得等了, 每次处理完上一个才能处理下一个, 如果想要并行处理这些请求, 就得相应地开10个线程, 请求一多起来, 那资源肯定抗不住

    ​	非阻塞IO, 这种方法每多一个请求就得多一套轮询, cpu顶不住

    ​	IO多路复用, 整一个单独的线程 , 专门用来轮询问结果, 接收请求的线程在收到请求时就往轮询线程使用的IO列表中添加一项, 这样的话, 接收请求的线程就能一直接收请求不阻塞. 而当某个IO操作完成后, 轮询线程也就问到了结果, 此时就可以再开一个工作线程处理这个结果.

    ​	总体看来, IO多路复用就是一个线程接客, 一个线程往后厨报菜并且不断的问做好了没, n个线程当服务员, 哪个菜做好了就呈上来.

    ![image-20210701181825606](操作系统.assets/image-20210701181825606.png)

*   信号驱动IO

*   异步IO

    ​	首先用户程序向内核程序发起IO操作的系统调用, 内核程序立即进行返回, 然后接近着执行用户程序指定的IO操作. 直到IO操作读完了, 并且把数据从内核空间转移到用户空间后, 内核程序通知用户程序数据已经读完了

    ​	因为内核程序一旦接收到系统调用就直接返回, 那么用户程序这边就不要任何等待, 直接就能往下执行程序, 所以用户程序全程都是非阻塞状态.

    ![image-20210701182943596](操作系统.assets/image-20210701182943596.png)

五种模型各阶段阻塞状态比较

​	只有异步IO是真正的全程无阻塞, 其他的多多少少都被阻塞了

![image-20210701183306710](操作系统.assets/image-20210701183306710.png)





#### 操作系统&网络交叉

###### 计算机如何接收网络数据?

[参考资料](https://blog.csdn.net/armlinuxww/article/details/92803381)

1.  以下是常规使用 ***recv系统调用*** 建立服务开启监听接收客户端数据的流程

    ```
        //创建socket 
        int s = socket(AF_INET, SOCK_STREAM, 0);    
        //绑定 
        bind(s, ...) 
        //监听 
        listen(s, ...) 
        //接受客户端连接 
        int c = accept(s, ...) 
        //接收客户端数据 
        recv(c, ...); 
        //将数据打印出来 
        printf(...) 
    ```

    

2.  执行到accept之前时, 操作系统会根据创建的socket在本地内存创建TCP/UDP缓存, 用于存放要发送和接收的数据

    ![image-20210701202625380](操作系统.assets/image-20210701202625380.png)

    socket包括:

    *   发送缓冲区
    *   接收缓冲区
    *   <span style="color:cyan;">等待列表  ( 这个是select慢的原因 )</span>

3.  recv 方法是阻塞方法

    执行到recv时, 将该用户进程置为阻塞状态, 并且把该进程的id设置到对应的 socket 的等待列表中 

    此时程序会一直等待直到收到客户端的请求

4.  操作系统内核程序中有一个程序专门用来处理网络数据, 将其称为A, 它使用一块内存上的内核空间称为M

    当网卡收到来自网络上的数据时, 网卡先直接把数据写到M上

5.  然后给cpu特定的针脚发送一个电信号, 比如发一个高电位到cpu的148引脚, 这代表着收到了网络数据

6.  cpu挨电之后直到来网络数据了, 就进入中断, 切换到内核程序-网卡数据处理程序A

7.  网卡处理程序拿出网络数据, 从中获取到对应的端口, 将其复制到指定端口对应的socket的接收缓冲区中

    然后获取到该socket的等待队列中相关的进程号, 将这些用户程序状态改为运行态

    最后把该用户进程号从等待队列中删除

8.  然后这个用到网络数据的用户程序就会在接下来的某个时间点被运行, 且此时它的socket中已经包含了网络数据



###### 服务器如何同时监控多个socket?

​	以上使用 系统调用recv 的方法只是开启了一个socket, 然后就进入阻塞直到有用户访问. 而服务器往往需要同时与多个客户端保持连接, 显然上述方法不能同时与多个客户端建立连接

​	一个进程同时监控多个socket的需求, 在早期的操作系统中均采用select的机制实现

​	select机制, 通常提供一个select()的系统调用, 接收一个socket列表, 在用户进程中, 先创建多个socket, 然后将其作为列表传给select系统调用, 此时用户进程进入阻塞, 直到某个socket接收到网络数据



```
    //首先创建一堆socket
    int s = socket(AF_INET, SOCK_STREAM, 0);   
    bind(s, ...) 
    listen(s, ...) 
     
    int fds[] =  存放需要监听的socket 
     
    while(1){
    	// 然后把这些socket传给select就进入阻塞等着它的返回
        int n = select(..., fds, ...) 
        // 收到数据时也不知道是哪个连接的数据, 还得自己遍历
        for(int i=0; i < fds.count; i++){ 
            if(FD_ISSET(fds[i], ...)){ 
                //fds[i]的数据处理 
            } 
        } 
    } 
```

​	select机制的底层实现是, 在调用select时, 将该用户进程逐个加入到socket列表每一项的等待队列中

​	当某个socket接收到网络数据时, 先把数据复制到对应的socket中, 然后找到等待列表中关联的进程号, 将这个进程置为运行态, 最后再遍历socket列表, 将等待列表逐个清空, 

​	而在用户程序这边, 因为不知道select函数的返回值是属于哪个连接的, 所以需要在接收到数据后, 也要遍历整个socket列表, 找到是哪个连接接收到了数据, 然后才能进行处理.

​	综上, 使用select系统调用时, ***每次接收到网络数据, 内核程序需要对所有socket遍历一次, 然后用户程序需要对所有socket遍历一次***, 如果连接数很大, 那么这里两次遍历将极大影响效率, 所以在最早期版本select系统调用中, 规定socket列表个数最多为1024, 稍后期的poll系统调用中, 取消了这个限制 



epoll

![image-20210701210808878](操作系统.assets/image-20210701210808878.png)

​	在后期的操作系统中, 又使用另外一种方法实现了一个进程监听多个socket连接, 这种机制称为epoll

​	epoll提供三个系统调用, epoll_create, epoll_ctl, epoll_wait

​	<span style="color:cyan;">epoll_create</span> 创建一个 epoll 对象并返回

​	epoll对象有一个list类型的属性rdlist, 用来存放已经接收到数据的socket的指针们

​	epoll对象有一个属性等待队列, 用来存放相关的进入阻塞的用户进程号

​	<span style="color:cyan;">epoll_ctl</span> 将 epoll对象设置到指定的socket列表中每一项的等待列表中

​	<span style="color:cyan;">epoll_wait</span>, 被调用时, 如果此时 epoll 对象中的 rdlist 为空, 则进程进入阻塞, 否则返回 rdlist 中的 socket指针们

​	当接收到网络数据时, cpu中断执行网络数据处理程序, 根据数据找到对应的socket并且把数据复制过去, 然后找到该socket的等待队列中设置的epoll对象, 把该socket的地址追加到epoll对象的rdlist中, 然后找到该epoll对象, 获取等待队列属性, 将这里面的用户进程设置为运行态, 接下来当用户进程恢复运行后, 可直接访问epoll对象的rdlist属性获取到该数据来自于哪个socket

​	因为每次接收到数据后, 不再需要遍历socket列表, 删除每一个中的等待队列, 这省去了原本select机制中的第一次遍历

​	同时当用户程序再次运行接收到数据时, 可直接从rdlist中获取到对应的socket引用, 那么就省去了用户程序对socket列表的第二次遍历

​	因为上面省去了select机制中最耗时的步骤, 所以epoll机制在性能上极大地优于select

使用指南

1.  首先使用epoll_create创建epoll对象, 也创建一堆socket对象
2.  然后使用epoll_ctl 将 epoll 对象设置到 socket对象的等待队列中
3.  最后调用epoll_wait接收这些socket中的网络数据

```
    // 整几个socket对象
    int s = socket(AF_INET, SOCK_STREAM, 0);    
    bind(s, ...) 
    listen(s, ...) 
     
    // 整一个epoll对象
    int epfd = epoll_create(...); 
    // 将 epoll 设置到每一个 socket 对象的等待队列中
    epoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中 
     
    while(1){ 
    	// 接收socket中的网络数据
        int n = epoll_wait(...) 
        for(接收到数据的socket){ 
            //处理 
        } 
    } 
```

​	



