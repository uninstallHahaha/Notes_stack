# **机器学习**

> sklearn 使用python实现的了各种机器学习基本算法的包



## [模型评估](https://zhuanlan.zhihu.com/p/114391603)

#### 模型验证

>   关于 训练集、验证集、测试集

![image-20211214171106789](机器学习.assets/image-20211214171106789.png)

​		通常对于同一个问题，我们会选取多个候选模型

​		为了能够验证各个模型的泛化能力，从而选择一个最佳的模型，需要将数据分为训练集和测试集，将模型在训练集上训练，对训练完成的多个模型，在测试集上进行测试，根据测试结果对各个模型的超参数进行调整，最后选出最优的模型

​		此时由于该模型是拟合训练集和测试集后的结果，所以无法得知其在真实数据分布上的效果，因此需要在一开始的时候将数据分为 训练集，验证集，测试集，三个部分，其中 训练集和验证集用于模型选择和超参数调整，待到选择出来最优模型及其超参数后，记录该模型以及超参数

​		因为训练数据的大小决定了模型的能力强弱，所以最后使用该模型，固定超参数，重新使用 训练集+验证集 进行训练，使用 测试集 对模型进行评估

​		因为测试集不作为训练数据，其中的数据是模型从未见过的，也不曾根据测试数据进行拟合，所以模型在测试数据上的表现能够客观地反应模型的泛化能力



#### 交叉验证

​		对于上述方案，需要将总数据分为三个部分，如果总数据量很小，除去测试集，剩下的数据怎样划分为 训练集和验证集 都将是个问题：如果训练集小，那么必然造成模型能力差；如果验证集小，那么验证结果不能够真实全面地反映出模型的真实评分。

​		交叉验证即，除去总是需要单列的测试集，将剩下的数据多次划分为训练集和验证集，然后使用这些多组数据进行验证，取多次验证结果的平均值作为验证误差来优化模型，这就是所谓的 “交叉验证”

交叉验证的方法

*   留一法

    假设总共m个样本，每次取出一个作为验证集，进行m次交叉验证，取验证误差平均值确定是得进行m次交叉验证和训练，巨费时间

*   K折交叉验证

    说白了就是把样本均分为k份，取其中一份作为验证集，那么交叉验证次数为k

*   多次K折交叉验证

    跟k折方法一样，不同之处在于将k折验证重复多次，每次的区别仅仅在于均分数据的位置不同

*   蒙特卡洛交叉验证

    就是将普通的随机划分训练集、验证集、测试集的步骤重复几次，然后取几次的验证误差平均值







#### 性能度量

###### 均方误差

说白了就是将所有样本点的预测结果与实际结果之间的差值加起来

![image-20211214172057293](机器学习.assets/image-20211214172057293.png)

![image-20211214172047657](机器学习.assets/image-20211214172047657.png)

如果预测出来的结果是带概率的结果，那么就给每一项上乘以这个概率值

![image-20211214172141498](机器学习.assets/image-20211214172141498.png)







###### 错误率

就是 `错的个数/总的个数`

![image-20211214172425938](机器学习.assets/image-20211214172425938.png)

其中，![image-20211214172536090](机器学习.assets/image-20211214172536090.png)代表后面括号里的成立则返回1, 否则返回0







###### 精度

就是 `1-错误率`

![image-20211214172713378](机器学习.assets/image-20211214172713378.png)





###### 代价敏感错误率

上述的错误率将所有出错的情况都记为1, 如果实际问题中每种错误都有不同的权重，那么就需要在计算错误率时就应当考虑权重

![image-20211214204346893](机器学习.assets/image-20211214204346893.png)

这个公式本质上就是 `所有错误权重之和/总样本个数`











###### 查准率和查全率

>   查准率简称 P
>
>   查全率简称 R

比如有100个结果，都是1或0, 真实分布是 60个1 和 40个0

预测结果是 70个1 和 30个0

那么这预测出来的结果 70个1 中， 肯定有真正是1的，也有真实是0的

于是就有如下表格

![image-20211214173533305](机器学习.assets/image-20211214173533305.png)

然后根据公式计算差准率和查全率

![image-20211214173600357](机器学习.assets/image-20211214173600357.png)



PR反向变动

![image-20211214195059476](机器学习.assets/image-20211214195059476.png)

​		根据分布混淆矩阵得知，P 和 R 是反向变动的，即  P 增大时， R减小

​		比如，预测结果变为 80个1 和 20个0 时，相当于表格中垂直的分割线向右移动，此时FN减小，FP增大，那么 P 减小，R 增大

​		所以，P 和 R 随着判别标准阈值的变化而变化，我们需要选取一个合适的阈值得到对应的 P 和 R 来作为判别一个模型性能的标准



为什么要有PR两个衡量标准？

​		对于判别5和非5问题，假设10个样本，其中只有一个样本是5, 那么模型只需要将所有结果都输出非5, 即可达到90%的正确率，这显然是不合理的

​		对于该问题，该模型的 P = 0, R = 0, 即可得知该模型并不ok



那么，如何选取合适的阈值并以此衡量一个模型的性能呢？

*   直接取P和R的交点，由上得知，P 和 R 呈反向关系，而我们需要尽可能地使得这两个值大，它们的图像大致如下，那么取交点位置，就是一个较为折衷的选择

    ![image-20211214192917290](机器学习.assets/image-20211214192917290.png)

*   F1调和平均数

    1/F1 = 1/2*(1/P+1/R)





利用P和R对多个模型性能进行比较

​		不同模型对应有不同的PR曲线，我们的原则是尽可能让 P 和 R 都较大，那么如下图

![image-20211214195255615](机器学习.assets/image-20211214195255615.png)

​		B曲线在R相同的情况下，P总是高于C曲线的值，那么就说明B模型总是优于C模型

​		而对于A曲线和B曲线，在不同的位置，它们的P和R的大小关系并不确定，此时可以根据曲线的面积等其他方式确定较优模型





TPR和FPR

![image-20211214200235133](机器学习.assets/image-20211214200235133.png)

​		由此可知，TP和TN是我们期望尽可能大的值，那么我们就希望 TPR 尽量的大，而FPR尽量地小

​		在判别阈值不断增大的过程中，预测结果中 TP 和 FP 也会随之增大，那么此时 TPR 和 FPR 都会增大，所以我们的衡量标准为，既然 TPR 和 FPR 都在增大，就选择 TPR 增速快而 FPR 增速的慢的模型

​		由此可以得出以下ROC曲线，其中应当选择阴影区域面积大的模型，为较优模型

![image-20211214200712880](机器学习.assets/image-20211214200712880.png)



###### ROC和AUC

上图，ROC为图中的曲线，AUC为曲线下面的阴影区域面积





###### rank-loss

`rank-loss=1-AUC`

rank-loss 就是上图中ROC曲线上面非AUC的区域面积









#### 假设检验

​		通常在模型训练完成后，会在测试集上计算其准确率，但是测试集毕竟不一定能够反映真实的数据集，那么如何检验在测试集上得到的这个正确率是否可信呢？

​		假设检验的方法就是，假设在测试集上得到的正确率是可信的，然后根据该正确率计算该模型预测结果的置信区间，最后再拿该模型对测试集进行测试，如果测试结果落到置信区间内，那么则认为该正确率可信

<span style='color:cyan;'>举例子</span>

​		对于一个模型，在测试集上得到的正确率是0.7，这意味着对于每个测试样例，都有0.7的概率预测正确，0.3的概率预测错误

那么，取十个测试用例, 预测正确10个的概率为 
$$
C^0_{10}(0.3)^0*(0.7)^{10}
$$
依次类推，预测正确9,8,7....个的概率为
$$
C^{1}_{10}(0.3)^1*(0.7)^{9} \\
C^{2}_{10}(0.3)^{2}*(0.7)^{8} \\
C^{2}_{10}(0.3)^{2}*(0.7)^{8} \\
...
$$
将这些概率计算出来，得到概率曲线，可以得知大致呈现正态分布，预测正确5个的概率最大

![image-20211215103912451](机器学习.assets/image-20211215103912451.png)

​		然后规定取90%为置信区间，也就是如果测试结果落在前90%的情况时，认为该正确率可信，否则不可信（因为后10%概率都很低几乎不能达到）











## 分类问题

### KNN

![image-20211221160313494](机器学习.assets/image-20211221160313494.png)

​		事先给出几类数据的分布, 然后对新的数据进行分类时, 首先给定一个k值，然后算得这个新数据与原样本点所有的距离，选择最近的k个样本点，使用这k个样本点的分类给新数据点进行投票分类

缺点：需要计算跟每一个样本数据的距离 , 所以如果样本数据的大小很影响运行效率



###### 使用knn的电影分类案例

```python
#导包
import numpy as np
import pandas as pd
from sklearn.neighbors import KNeighborsClassifier

#加载数据
#只加载第一个sheet中的内容
movie = pd.read_excel('./knn表.xls',sheet_name=0)
movie

#取出决定类型的数据
X = movie[['武打镜头','接吻镜头']]
X
#取出分类结果数据
y = movie['分类情况']
y

#初始化一个分类器 , 设置使用投票的数据数量为 5
knn = KNeighborsClassifier(n_neighbors = 5)

#传入数据和分类结果训练分类器
knn.fit(X,y)

#对新数据进行分类
X_test = pd.DataFrame({'武打镜头':[100], '接吻镜头':[3]})
X_test
#返回预测的分类结果
knn.predict(X_test)
#返回预测分类的概率
knn.predict_proba(X_test)

#原理 : 分别求新数据与原来数据的距离, 然后从小到大排列, 然后取前n_neighbors的数据, 使用它们的 分类情况 进行投票, 最后返回票数最多的那个分类
```

###### 使用knn进行手写文字的识别

> 首先准备数据:  
>
> 10 个文件夹, 文件夹命名分别为 0 ~ 9
>
> 每个文件夹下存放该文件夹对应数字的类型为 bmp类型的手写数据文件500个 , 命名为 x_xxx.bmp , 这些文件应当都是黑白图

```python
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.neighbors import KNeignborsClassifier

#读取数据
data = []
for i in range(10):
    for j in range(1,501):
        data.append( plt.imread('./%d/%d_%d.bmp' % (i,i,j)) )
        
data
len(data)
X = np.array(data)

#创建初始的分类数据
#前500个是0, 500~1000个是1, 以此类推
y = [0,1,2,3,4,5,6,7,8,9]*500
y = np.array(y)
y.sort()
y

#随机选4000个数据作为训练模型使用的数据
#随机选1000个数据作为测试模型使用的数据
#此时 X_train 是三维数据 , 而knn只接受二维的样本数据, 所以要把数据转换为二维的, reshape时第二个参数为图片的宽*高, 也就是将图片的二维数据转换为一维数据, 因为knn只是计算距离, 所以样本数据的二维信息对它来说没有用
index = np.random.randint(0,5000,size=4000)
X_train = X[index]
X_train = X_train.reshape(4000, [图片的宽*高])
y_train = y[index]

index = np.random.randint(0,5000,size=1000)
X_test = X[index]
X_test = X_test.reshape(1000, [图片的宽*高])
y_test = y[index]

#使用样本训练模型
#初始化分类器时, 可以调整 n_neighbors 来优化分类结果, 也可以设置 weights 方式来优化
#设置 p 指定使用的距离计量方式
knn = KNeighborsClassifier(n_neighbors = 5)
knn.fit(X_train, y_train)

#预测测试数据
y_ = knn.predict(X_test)
#对比预测结果和真实结果
y_[:20]
y_test[:20]
(y_ == y_test).mean()
knn.score(X_test, y_test)
```

###### knn准确率提升

```python
# 1. 调整分类器的参数

# 2. 归一化样本数据
# 如果样本数据各个属性的取值范围差距很大, 那么在求距离的过程中就相当于给这些属性加上了权重, 但是这并不是我们想要的, 因为每个属性的权重应当是一致的
#导包
from sklearn.preprocessing import StandardScaler
#获取归一化器
s = StandardScaler()
#归一化样本, X是样本数据
X2 = s.fit_transform(X)
X2
```



###### sklearn中的分割数据

> 将数据按照指定的比例随机分割为 训练数据和测试数据

```python
#导包
from sklearn.model_selection import train_test_split

#原数据
data = np.arange(100)

#分割数据
d_train, d_test = train_test_split(data, test_size=0.2)

#显示分割结果
display(d_train, d_test)
```

###### sklearn保存训练好的分类器

```python
#导包
from sklearn.externals import joblib

#存储模型为文件
joblib.dump(knn, './model')

#加载模型文件
model = joblib.load('./model')
model

#knn模型在保存时, 保存每一个样本点, 所以保存的文件较大
```

### Logistics 回归

> 虽然使用的是线性回归的方法, 求出的是线性函数, 但是该方法用于 **分类** 问题, 因为在其求出线性函数之后, 使用 sigmod 函数将函数的 y 的范围限制在 0~1 之间, 那么返回的就是各个分类的概率, 然后选择概率最大的分类作为结果范围,  使其变成一个处理分类问题的模型

```python
#导包
from sklearn.linear_model import LogisticRegression

#获取❀花分类问题的数据
import sklearn.datasets as datasets
iris = datasets.load_iris()
iris
#150个拥有4个属性的样本
X = iris['data']
y = iris['target']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y)
#使用Logistic模型训练数据
lg = LogisticRegression()
lg.fit(X_train, y_train)
y_ = lg.predict(X_test)
display(y_, y_test)
#查看各个分类的概率结果
lg.predict_proba(X_test)
#查看求解出的线性方程的系数
lg.coef_
```



## 回归问题

> 回归问题就是找出变量之间的函数关系, 然后使用这个函数对未来的值进行预测

### 总体方法 : 最小二乘法求函数

> 就是求 预测函数 和 真实函数 的差值的二次方的最小值, 这个值越小, 预测函数越接近真实函数

### 线性回归

#### 方法 : 矩阵运算求函数

> 假设样本有 n 个属性 , 那么线性回归求出来的函数就是 n 元一次方程 , 线性回归计算器返回的目标方程系数就有 n 个
>
> 换一个思路 : 这个求得的 n 个系数就是这 n 个属性的权重

```python
#导入sklearn 中自带的数据集
import sklearn.datasets as datasets

#获取波士顿房价数据 , 这个数据集属于回归问题数据集, 因为样本结果不是有限个分类, 而是无限个数字
data = datasets.load_boston()
data

#获取样本值
X = data['data']
X.shape

#获取样本对应的结果
y = data['target']
y.shape

#导入线性回归工具包
from sklearn.linear_model import LinearRegression

#分割数据为样本数据和测试数据
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)

#创建一个线性回归计算器 - 用来计算 x 和 y 之间的函数关系
#设置 fit_intercept = False , 设置计算出来的函数不包含截距, 也就是函数过原点
lr = LinearRegression(fit_intercept = False)

#使用线性回归计算器计算目标函数
lr.fit(X_train, y_train)

#预测测试数据的结果
lr.predict(X_test).round(2)

#对比真实结果
y_test

#查看求出的线性函数的参数, 这里样本数据有 13个属性,这个返回的参数列表就有 13 个元素
W_ = lr.coef_
w_

#查看结果函数的截距, 前面设置了不要截距, 那么返回的就是0
b_ = lr.intercept_
b_

#实际上 lr.predict() 就相当于系数矩阵 w_ 乘 测试的数据
X_test.dot(w_)
```

### Ridge 回归

#### 方法 : 梯度下降求函数最值

> **思路** : 在导数方向上进行固定步幅的移动, 越接近最值, x每次移动的值就越小( 因为导数会越来越小 ), 当x单次移动的值小于设定的值时, 即为近似的最值
>
> **实现** : 首先函数是一元二次函数, 
>
> ​	在函数上随机选择一个点, 设置导数方向每次移动的步幅 step, 设置一个精确度 p, 即当 x 单次移动量不超过这个值时, 终止移动
>
> ​	 然后无限循环, 每一次使得 x 移动导数方向上 step 距离对应的 x 的距离 , 直至 x 单次移动的值小于精确度 , 终止循环, 此时 x 即为近似的结果
>
> **关于 step** : 不能设置太大, 否则会跨过最值从而导致 x 无限增大
>
> 在sklearn的 LinearRegression 中, 如果设置了求截距, 那么它会使用梯度下降的方法求截距和参数.

> **拟合** : 使用线性回归的方法求解通用函数的系数的过程, 就称为 拟合
>
> **过拟合** : 求出的函数系数特别多, 或者系数特别大 , 那么函数不具有普遍适用性, 只有在数据的属性高度符合条件时, 才能给出相对正确的结果 , 就是学习特征的过程中学过头了.
>
> 换种方式理解 , 就是求出的函数顾虑了( 经过 )太多的样本点, 从而呈现出剧烈地不稳定性(百转千回), 而不是一条平滑的曲线或直线 , 这就使得系数们( 斜率 )变得很大,   那么在预测新数据时, 就不能很好的给出结果.
>
> **函数正则化** : 对于求解出来的函数 , 如果各个系数波动很大, 那么这个函数则不稳定.
>
> 正则化就是使得各个系数都在一个合适的范围内. 从而防止出现过拟合的情况 , 使得求出的函数具有普遍适应性.
>
> **Ridge回归就是使得求出函数的系数变小的线性回归方法**
>
> **Ridge回归是 线性回归的优化算法 , 是实现了L2正则化的线性回归算法**
>
> **L2正则化** : 在最小二乘法的损失函数基础上, 添加一个系数和的二次方 , 使用该二次方项来约束目标函数的系数使其变小

```python
#导包
import numpy as np
from sklearn.linear_model import LinearRegression, Ridge
import sklearn.datasets as datasets

#使用内置的波士顿房价数据
boston = datasets.load_bostom()
X = boston['data']
y = boston['target']

#切割数据
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)

#使用线性回归
lr = LinearRegression()
lr.fit(X_train, y_train)
display( lr.coef_, lr.score(X_test, y_test) )

#使用Ridge回归
#alpha 设置求解回归函数的方程中的 a 的值, 具体如何求解可在 sklearn 官网查看
#tol 设置精确度
#max_iter 设置最大迭代次数
ridge = Ridge(alpha=10)
ridge.fit(X_train, y_train)
display(ridge.coef_, ridge.score(X_test, y_test))

#对比两个回归方式得出的 coef_ , 可发现 Ridge 回归中的 coef_ 相对更接近于 0 
```

### Lasso 回归

> **Lasso回归是 线性回归的优化算法 , 是实现了L1正则化的线性回归算法**
>
> **L1正则化** : 在原最小二乘法损失函数的基础上, 添加了系数和的一次项, 使用这个一次项来约目标函数使其系数***归零***或减小

```python
#导包
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.linear_model import LinearRegression, Ridge, Lasso

#生成数据
#有200个属性的样本50个
X = np.random.randn(50,200)
X
#生成系数w
w = np.random.randn(200)
w
#随机选择190个系数使其为0
index = np.arange(200)
np.random.shuffle(index)
index
w[index[:190]] = 0
w
#生成目标值 y
y = X.dot(w)

#分别使用三种回归方式求系数
lr = LinearRegression(fit_intercept=False)
ridge = Ridge(alpha=1, fit_intercept=False)
lasso = Lasso(alpha=0.1, fit_intercept=False)

lr.fit(X,y)
ridge.fit(X,y)
lasso.fit(X,y)

#得到三种回归方式求得的系数
lr_w = lr.coef_
ridge_w = ridge.coef_
lasso_w = lasso.coef_

#将真实系数和三种方式求得的系数画图表示
plt.figure(figsize= (12,9))
ax = plt.subplot(2,2,1)
ax.plot(w)
ax.set_title('真实系数')

ax = plt.subplot(2,2,2)
ax.plot(lr_w)
ax.set_title('线性回归')

ax = plt.subplot(2,2,3)
ax.plot(ridge_w)
ax.set_title('ridge回归')

ax = plt.subplot(2,2,1)
ax.plot(lasso_w)
ax.set_title('lasso回归')

#对于该问题,因为真实系数属于稀松矩阵,大部分都是零, 而lasso回归将大部分系数都归为0, 所以在该问题中, lasso表现更好
```

### 回归算法人脸补全

```python
#导包
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.linear_model import LinearRegression, Ridge, Lasso
#使用knn求解线性函数的模型
from sklearn.neighbors import KNeighborsRegressor
import sklearn.datasets as datasets

#获取数据
faces = datasets.fetch_olivetti_faces()
faces
data = faces['images']
#400张64*64的图片
data.shape

#随机选择一张图片预览
index = np.random.randint(400,size=1)[0]
plt.imshow(data[index], cmap=plt.cm.gray)

#上下分割这400张图片, 上半部分作为 X 样本数据, 下半部分作为 y 目标数据
#然后将数据改成二维的方便之后训练
X = data[:,:32].reshape(400,-1)
y = data[:,32:].reshape(400,-1)

#分割数据为训练数据和测试数据
from sklearn.model_selection import train_test_split
#保留10条数据作为测试数据
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 10)
X_train.shape

#随机选择一张图片预览上下分割效果
index = np.random.randint(390,size=1)[0]
face_up = X_train[index].reshape(32,64)
face_down = y_train[index].reshape(32,64)
ax = plt.subplot(1,2,1)
ax.imshow(face_up, cmap=plt.cm.gray)
ax = plt.subplot(1,2,2)
ax.imshow(face_down, cmap=plt.cm.gray)

#分别使用四种回归算法进行函数的计算
es  = {}
es['knn'] = KNeighborsRegressor(n_neighbors=5)
es['lr'] = LinearRegression()
es['ridge'] = Ridge(alpha=1)
es['lasso'] = Lasso(alpha=1)
predict_ = {}
for key, model in es.items():
	model.fit(X_train, y_train)
	y_ = model.predict(X_test)
	predict_[key] = y_
    
#显示各种算法预测的结果 10行6列
plt.figure(figsize=(6*2, 10*2))
for i in range(10):
    #第一列 , 真实的整个人脸
    ax = plt.subplot(10, 6, 1+i*6)
    face_up = X_test[i].reshape(32,64)
    face_down = y_test[i].reshape(32,64)
    ax.imshow(np.concatenate([face_up, face_down], axis=0),cmap='gray')
    ax.axis('off')
    ax.set_title('true')
    
    #第二列 , 上半个人脸
    ax = plt.subplot(10, 6, 2+i*6)
    face_up = X_test[i].reshape(32,64)
    ax.imshow(face_up ,cmap='gray')
    ax.axis('off')
    ax.set_title('face_up')

    #3,4,5,6列, 各种算法预测的下半张人脸
    for j,key in enumerate(predict_):
        ax = plt.subplot(10, 6, 3+j+i*6)
        y_ = predict_[key]
        face_down_ = y_[i].reshape(32,64)
        ax.imshow(np.concatenate([face_up, face_down_], axis=0), cmap = plt.cm.gray)
        ax.axis('off')
        ax.set_title(key)
        
```



## 聚类问题

给定数据集，样本数据无标签，需要根据其分布情况生成聚类



#### K-means 聚类

> 1. 打算把一堆点分成 k 类
> 2. 先随机选 k 个点 , 将这 k 个点周围离它相对近的点分为一类
> 3. 将生成的几个类别中的重心点作为这一类的中心点, 再次按照周围离它较近的点划分为一类
> 4. 循环以上两步最终将得到分类

![1614045798114](机器学习.assets/1614045798114.png)

足球队梯队聚类

```python
#上图为使用到的数据集 , 读取到 data 变量中
#使用 k-means 对足球队水平进行聚类
from sklearn.cluster import KMeans

X = data.iloc[:,1:]
#创建聚类算法
#n_cluster 设置分为几类
kmeans = KMeans(n_cluster=3)
#fit数据, 没有标签, 不需要y
kmeans.fit(X)
#查看聚类结果
y_ = kmeans.predict(X)
y_
#分为三类, 分别是 0, 1, 2
for i in range(3):
    print((data['国家'].values)[np.argwhere(y_==i).ravel()])
```

```python
import sklearn.datasets as datasets

#生成三个聚类的每个元素包含两个特征值且总数为100个的样本点
X,y = datasets.make_blobs()
plt.scatter(X[:,0], X[:,1], c=y)

#使用kmeans进行聚类, 如果设置的分类数不符合样本数据本身的分类情况, 那么多次执行聚类会发现其分类结果都不相同
kmeans = KMeans(5)
kmeans.fit(X)
y_ = kmeans.predict(X)
plt.scatter(X[:,0], X[:,1], c=y_)

#使用轮廓系数来评价聚类得分, 分越高越好
from sklearn.metrics import silhouette_score
silhouette_score(X, y_)
```





#### 密度聚类(DBSCAN)

​		选取起始点，以该点为圆心，做指定半径的圆形，在圆形范围内的样本点被标记为一类，且不断画圆扩张，直至所有扩张点包含的样本点数量小于给定阈值







#### 层次聚类

每次将距离最近的点分为一类，并更新聚类的中心位置，多次聚类合并，直至聚为一类

在某层聚类中进行截取，可以获得任意分类数的聚类结果

![image-20211221154432468](机器学习.assets/image-20211221154432468.png)











## 决策树:分类问题

### 信息熵

>   信息熵用来衡量信息的确定情况
>
>   具体来说，信息熵就是用来形容一个随机事件模型等同于抛几个硬币的问题，比如信息熵为 1bit 则相当于抛一个硬币的问题

***如何衡量事件的信息熵***

*   等概率事件

​		比如我去买一个瓜，且我并不了解如何挑一个好瓜，那么我买到好瓜的概率就是一半，1/2，这个问题等价于抛一个硬币，此时正反的几率是相同的，都是 50%，此时该事件的信息熵就是 1bit

依次类推，存在4种等可能情况的事件，等同于抛两个硬币问题，那么它的信息熵就是 2bit

由此得出，在等概率事件中，信息熵的计算方式为 
$$
n = log_2^m  (m是等概率事件的个数)
$$


*   不等概率事件

    ​		不等概率问题可以转换为等概率问题

    ​		比如问题中有三种事件，A:1/2, B:1/3, C:1/6, 那么它们可以等价为6个等概率事件，如下图，每个不等概率事件或多或少相当于多个等概率事件 

    ![image-20211215191914949](机器学习.assets/image-20211215191914949.png)

    那么 A事件，B事件，C事件包含的信息熵分别为
    $$
    n_A = \frac{1}{2}(log_2^6-log_2^3)=\frac{1}{2}log_2^{\frac{6}{3}}=-\frac{1}{2}log_2^{\frac{3}{6}}=-\frac{1}{2}log_2^{\frac{1}{2}}\\
    n_B = \frac{1}{3}(log_2^6-log_2^2)=\frac{1}{3}log_2^{\frac{6}{2}}=-\frac{1}{3}log_2^{\frac{2}{6}}=-\frac{1}{3}log_2^{\frac{1}{3}}\\
    n_C = \frac{1}{6}(log_2^6-log_2^1)=\frac{1}{6}log_2^{\frac{6}{1}}=-\frac{1}{6}log_2^{\frac{1}{6}}=-\frac{1}{6}log_2^{\frac{1}{6}}
    $$
    那么该事件总的信息熵为 
    $$
    n = n_A+n_B+n_C = -\sum_{k=1}^{|y|}p_klog_2^{P_k}
    $$
    



***通过信息熵量化信息***

​		既然信息熵是用来形容一个事件模型包含多少确定因素，那么对于一个问题，在对其提供一条信息的前后，其信息熵是不同的，此时可以使用前后两个信息熵之差来量化该信息的容量

举例子

​		一道有ABCD四个选项的选择题，在什么都不知道的情况下，四个选项的概率都是 1/4，此时计算得知信息熵为 2, 然后提供一条信息：“C选项的概率是1/2”，那么此时计算得知信息熵为 1.79, 那么该条信息的容量为 `2-1.79=0.21`

![image-20211215192939924](机器学习.assets/image-20211215192939924.png)





***通过量化信息生成决策树***

​		分别计算每类信息的信息容量，依次从大到小作为生成决策树的分支条件，每个分支都是一个属性，直至分至叶子节点，得到最终分类结果

![image-20211215194033976](机器学习.assets/image-20211215194033976.png)







### 基尼系数

​		基尼系数用来衡量一个属性对分类结果的作用程度，因此可以通过计算比较基尼系数然后生成决策树

举例子

有三个属性用来判断是否得了心脏病

![image-20211215202109248](机器学习.assets/image-20211215202109248.png)

​		然后根据统计，可得知，根据不同属性的值，可以将数据进行分类，显然如果经过某个属性进行划分后，如果是否得了心脏病被清晰地划分在不同的部分，那么该属性对分类结果的作用就大

![image-20211215202307086](机器学习.assets/image-20211215202307086.png)

​		基尼系数就是计算一个经过属性一个属性的分类后，数据被正确划分的程度，具体来说


$$
基尼系数 = 在一批分类结果中（上图的绿色块）随机选择两个样本，它们不同的概率\\
=1-（在一批分类结果中随机选择两个样本，它们相同的概率）\\
比如对于左上角绿色块\\
=1-[(\frac{105}{105+39})^2+(\frac{39}{105+39})^2]\approx0.39
$$
​		

​		由此可得，一个属性的基尼系数越大，代表根据它划分后的数据越不纯，所以应当依次选择较小的基尼系数属性来生成决策树











### CART生成决策树

CART算法同样作为生成决策树的一种方法，是sklearn中使用的生成决策树算法

​		假设样本分布如图中黄色的点，该样本可以使用决策树来表示，那么如何确定决策树中每个分支的阈值？

​		CART算法，就是从0开始作为阈值（y轴，绿色的线），计算得出每个阈值下其他所有黄色的点到绿色线的直线距离之和（均方差），取均方差最小的阈值作为决策树分叉条件，该思想等同于线性回归，就是计算能将数据分为两部分的最佳直线

![image-20211215205500416](机器学习.assets/image-20211215205500416.png)







### 决策树剪枝

​		在生成完整的决策树后，往往并不是所有的树枝都对决策结果有积极作用，因此需要对决策树进行剪枝

剪枝分为两种

*   前剪枝

    ​		使用训练数据对决策树进行剪枝，对于训练数据，如果某个分支存在的时提供的分类正确率还不如分支前，那么剪掉该枝

*   后剪枝

    ​		使用测试数据对决策树进行剪枝，使用测试数据判断枝干是否对提高正确率有积极作用，否则剪枝







### 单个决策树

> **决策树** : 对于一个通过判别多个条件后可以将样本完成分类的问题 , 可以构建成一个决策树. 就是每次按照一个条件去分类, 直至最后将所有的数据都分类完成.
>
> **信息熵** : 使用信息熵衡量一个系统中信息的有序程度, 这个值越大 , 系统的信息越无序 
>
> ***那么如何构建这个决策树, 才能使得每次决策进行得更加高效 ?***
>
> ​	使用 香农的 **信息传送速率公式** 可计算出不同结构的决策树对信息整理的高效程度, 通过计算不同决策树的信息传送速率, 比较之后选择速率最高的方式, 即为最高效的决策树结构
>
> sklearn中使用的决策树为 CART 方式, 即二叉树.
>
> **决策树的生成** : 使用指定的标准分别计算以各个属性作为树的第一层时拥有最大信息增益的情况, 使用这种情况构建决策树的第一层, 以此类推, 直至将所有属性都安排为树的枝干 , 此时即为一颗完成的决策树. 

```python
#导包
import numpy as np
from sklearn.tree import DecisionTreeClassifier
import sklearn.datasets as datasets

#获取数据
iris = datasets.load_iris()
X = iris['data']
y = iris['target']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

#使用决策树分类器分类
#criterion 设置生成决策树使用的标准, entropy为信息熵
#max_depth 设置生成决策树的最大深度
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
clf.score(X_test, y_test)

#绘制决策树图形
#需要事先安装 pip install graphviz
#需要事先安装 graphviz-2.38.msi 这个软件, 软件安装完要配置环境变量
import graphviz
from sklearn import tree
data = tree.export_graphviz(clf, out_file=None,
                           feature_names = iris.feature_names,
                           class_names = iris.target_names,
                           filled = True)
graph = graphviz.Source(data)
graph
#保存决策树为pdf
graph.render('./iris')
#从文件中读取决策树
with open('./iris.pdf') as fp:
    dot = fp.read()
graphgiz.Source(dot)
```

> 单颗决策树进行分类可能效果不佳 , 实际生产中并不会使用单个决策树, 而是使用多个决策树共同决策的森林.

### 决策树森林

> **随机决策树森林** : 随机选取训练数据的多个子集训练生成多个决策树, 在进行分类预测时多个树同时给出结果, 然后选取这些结果中数量最多的分类作为结果输出.
>
> **极度随机决策树森林** : 在随机决策树森林的基础上, 把树中每个节点的分类值( 阈值 )改为随机生成并选取信息增益最大的分类值( 阈值 ). 

```python
#随机决策树森林
from sklearn.ensemble import RandomForestClassifier

#构建随机森林分类器
#n_estimators 指定使用多少个决策树, 默认10个
forest = RandomForestClassifier(n_estimators=20)
#训练和预测
forest.fit(X_train, y_train)
forest.score(X_test, y_test)

#极度随机决策树森林
from sklearn.ensemble import ExtraTreesClassifier
extra = ExtraTreesClassifier()
extra.fit(X_train, y_train)
extra.score(X_test, y_test)
```

### AdaBoost决策树

> 首先设置样本数据中每个属性的权重都相同, 生成第一个决策树, 然后多次迭代生成决策树, 每次迭代都根据上一次的分类结果将属性权重进行调整 ,  最后将这些决策树线性组合成为一个最后的决策树作为分类器输出

```python
from sklearn.ensemble import AdaBoostClassifier
#from sklearn.model_selectin import cross_val_score

ada = AdaBoostClassifier()
ada.fit(X_train, y_train)
ada.score(X_test, y_test)
```

### 梯度提升决策树 : 分类/回归

> 可以处理分类问题, 也可处理回归问题
>
> 构建多个根据不同属性进行分类的深度为1的决策树, 每个树中的每一种分支对应一个值, 处理回归问题时, 将数据遍历经过每一个树的到的结果加起来返回为预测值.

```python
#处理回归问题
from sklearn.ensemble import GradienBoostingClassifier
from sklearn.ensemble import GradienBoostingRegressor
from pandas import Series, DataFrame

#准备数据, 两个属性, 使用这两个属性回归计算用户的年龄 
X = DataFrame({'购物':[500,500,1500,1500], '是否百度回答': [0,1,0,1]})
y = np.array([14,16,24,26])

#使用梯度提升决策树回归
gbdt = GradienBoostingClassifier()
gbdt.fit(X,y)
#生成的决策树们
gbdt.estimators_
```

### XGBoost 决策树

> 对梯度提升决策树的改进
>
> 可处理分类问题和回归问题
>
> 使用该算法需要 pip install XGBoost
>
> 使用方法同 sklearn 中各种分类器的使用

### LightGBM 决策树

> 微软开发的, 对梯度提升决策树的改进
>
> 使用该算法需要 pip install lightgbm
>
> 使用方法同 sklearn 中各种分类器的使用







## Supprot Vector Mechine





### Max Margin Classifier

对于两批数据，可以通过使用它们边界样本点中间位置作为分界线来对两批数据进行划分

![image-20211215213758780](机器学习.assets/image-20211215213758780.png)

​		这通常是符合逻辑效果不错的，但是一旦出现某个异常数据点，将会极大地影响分界线的位置，这样进行的划分可以说是完全错误的

![image-20211215213900700](机器学习.assets/image-20211215213900700.png)













### Support Vector Classifier

​		svc用于解决mmc中因为异常样本造成的重大误差问题

​		通过交叉验证等方法，从两批数据中选择出来具有代表性的两个点，用来分别表示两批数据，然后使用这两个点作为边界点计算得知分界点

​		这些超出边界点的数据点被称为支持向量







### SVM

​		支持向量机，就是使用了支持向量的方法对数据进行划分的“机器”，添加了自适应维度的机制，如果一批数据在当前维度无法被划分，如下图，那么就对该数据进行升维映射到高维度，然后再进行支持向量划分，如下下图

![image-20211216092752379](机器学习.assets/image-20211216092752379.png)

![image-20211216092809450](机器学习.assets/image-20211216092809450.png)





###### 点到直线的距离

假设直线为 
$$
Ax+By+b=0
$$
那么点 `(x_0,y_0)`, 到该直线的距离为
$$
d = \frac{|Ax_0+By_0+b|}{\sqrt{A^2+B^2}}
$$
对于可能存在多个维度的向量 w，可以将其表示为超平面 (w,b)

那么与 w 维度相同的向量 x 到该超平面的距离为
$$
r= \frac{|w^Tx+b|}{||w||} \\
其中, ||w||表示\sqrt{w_1^2+w_2^2+...}
$$




###### SVM问题的核心

SVM问题的核心在于如何求得数据集分割线（超平面）

对于一维的数据集，可以使用一个点来进行分割，此时分割点的方程为
$$
w_1x_1+b=0 \\
x_1=-\frac{b}{w_1}
$$
对于二维的数据集，可以使用一条线来进行分割，此时的分割线方程为
$$
w_1x_1+w_2x_2+b=0
$$
依次类推，分割超平面的方程为
$$
w_1x_1+w_2x_2+...+b=0
$$
那么问题就可以总结为，求得最佳分割线中 向量w的各个分量，即w1,w2...，以及 b的值，这样就能确定一个分割超平面

那么如何确定一条最佳的分割线呢？

显然能够将数据集分割的更开的分割线最佳，也就是两批数据中数据点到分割线的距离最大为最佳

以二维数据为例，我们要计算的是一条分割线，将数据分为两份，一份都记为 +1，一份都记为 -1，假设该分割线为
$$
w_1x_1+w_2x_2+b=0
$$
那么在分割线上的点都符合该公式

在分割线上面的点应当为
$$
w_1x_1+w_2x_2+b>0
$$
在分割线下面的点应当为
$$
w_1x_1+w_2x_2+b<0
$$
现从两批数据中确定两个边界点，如图所示，人为规定它们分别为

![image-20211216175036463](机器学习.assets/image-20211216175036463.png)
$$
w_1x_1+w_2x_2+b=1\\
和\\
w_1x_1+w_2x_2+b=-1
$$
 那么此时可以通过这两个点量化分割线的分割效果，即两个点到分割线的距离之和，为
$$
r=\frac{|w_1x_1+w_2x_2+b|}{||w||} + \frac{|w_1x_1+w_2x_2+b|}{||w||} \\
=\frac{|1|}{||w||} + \frac{|-1|}{||w||}\\
=\frac{2}{||w||}
$$
同时包含一个约束条件，即
$$
s.t. \ y_i(w^Tx^i+b)\geq1,\ i=1,2,3...,m\\
其中y_i取值为+1或-1,\ |w^Tx^i+b|\geq1,\ 所以得出上述约束
$$
此时问题转化为，求在w取什么值时，r能取最大值，即
$$
\underset{w,b}{\max}\frac{2}{||w||}\\
显然需要最大化这个式子，本质就是最小化||w||\\
这同时等价于最小化||w||^2\\
那么问题就转化为 \\
\underset{w,b}{\min}\frac{1}{2}{||w||^2}\\
假设w包含两个分量w_1和w_2,那么该式子等于
\underset{w}{\min}\frac{1}{2}{(w_1^2+w_2^2)}\\
也就是求f(w_1,w_2)=\frac{1}{2}{(w_1^2+w_2^2)}取最小值时w_1和w_2的取值
$$
接着带上约束条件，这就顺势转换为拉格朗日乘子法问题，即，求在一个（多个）函数约束下，另外一个函数的最小取值时各个分量的值
$$
{
\underset{w}{\min}\frac{1}{2}{(w_1^2+w_2^2)} 
\atop 
s.t. \ y_i(w^Tx^i+b)\geq1,\ i=1,2,3...,m
}\\
其中 y_i 和 x_i 是已知的值
$$
因为拉格朗日乘子法的另外一种形式为，将约束函数与原函数结合为一个函数，然后在这个函数中对各个变量求偏导使其等于0，最后得到方程组，进而求得各个变量，即

![image-20211216194443978](机器学习.assets/image-20211216194443978.png)

![image-20211216194451109](机器学习.assets/image-20211216194451109.png)

![image-20211216194458230](机器学习.assets/image-20211216194458230.png)

得到三个函数
$$
\frac{F}{\partial{x}}=0 \\
\frac{F}{\partial{y}}=0 \\
\frac{F}{\partial{z}}=0
$$
对这三个函数求解即可得出各个变量的值

同样，该问题同样可以使用这种形式表示，即
$$
F=\frac{1}{2}||w||^2+\sum^{m}_{i=1}\alpha_i[1-y_i(w^Tx_i+b)]\\
此时包含三个约束\\
\alpha_i\geq0\\
y_if(x_i)-1\geq0\\
\alpha_i(y_if(x_i)-1)=0
$$
接下来对该式子各个变量求偏导并使其等于0
$$
w=\sum^{m}_{i=1}\alpha_iy_ix_i\\
0=\sum^{m}_{i=1}\alpha_iy_i
$$
这个求偏导的问题，可以等价地转换为其对偶问题，即求以下式子
$$
\max_{\alpha}\sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jx_ix_j
$$
即可求得各个变量值, 得到分割线函数





###### 核函数

​		如果原数据分布无法在当前维度进行分割，那么需要对原数据集进行升维处理，然后再进行分割

​		也就是将原来的样本 x ，经过某个函数处理后，变为 
$$
\phi(x)
$$
​		那么此时求分割超平面的对偶问题变为
$$
\max_{\alpha}\sum_{i=1}^{m}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_j\phi(x_i)^T\phi(x_j)
$$
​		注意其中包含升维函数相关的部分为 
$$
\phi(x_i)^T\phi(x_j)
$$
​		而在实际的问题中，该升维函数的计算可能极为复杂

​		此时可以使用核函数技巧简化计算

​		具体来说，就是使用原维度的样本数据 x 进行运算，得到与 ![image-20211219154437201](机器学习.assets/image-20211219154437201.png) 相同的计算结果，也就是这样
$$
使用函数k对原维度的数据进行计算，得到等同于升维后数据的计算结果\\
k(x_i,x_j)=\phi(x_i)^T\phi(x_j)
$$
举例子

首先升维函数如图所示

![image-20211219155003080](机器学习.assets/image-20211219155003080.png)
$$
经验证得知\\
(a^Tb)^2=\phi(a)^T\phi(b)\\
那么核函数 k=(a^Tb)^2
$$
![image-20211219155048693](机器学习.assets/image-20211219155048693.png)

这里使用原维度样本数据进行的计算部分被称为核函数，不同的核函数代表不同的升维函数，同一个核函数也可能等同于多种升维函数的效果

因此，<span style='color:cyan;'>切换核函数就是在切换升维函数，不同的升维函数能够带来不同的分割效果</span>



核函数实践指南

​		对于实际的问题，应当通过尝试后根据分割效果决定使用哪个核函数，不同的核函数会提供不同的函数参数供调整，对于这些参数，应当采用网格遍历法挨个试试，选择效果好的参数作为结果



sklearn中的核函数

![image-20211219160039967](机器学习.assets/image-20211219160039967.png)













## 朴素贝叶斯:分类问题

> [贝叶斯公式](https://www.matongxue.com/madocs/279) : 求在一个指定事件B发生的前提下, 另外的一个事件A 或一组事件A1~An 发生的概率的公式
>
> sklearn 中对贝叶斯公式采用了 独立性假设, 
>
> ​	即事件组 A1~An 都是独立发生的, 
>
> ​	此时 P(A1,...,An) = P(A1)* ... *P(An) , P(A1,...,An | B) = P(A1|B) * ... * P(An|B)

贝叶斯分类的理论依据来源于以下公式
$$
P(A|B) = \frac{P(A|B)P(B)}{P(A)}\\
换个形式，明朗很多\\
P(类别|特征) = \frac{P(特征|类别)P(类别)}{P(特征)}
$$








### 使用贝叶斯对三种数据模型分类

1. #### 正态分布 ( 高斯情况 )

2. #### 二分布( 投硬币 ) ( 伯努利情况 )

3. #### 多均匀分布( 掷骰子 )

```python
import matplotlib.pyplot as plt
%matplotlib inline

#导包
from sklearn.naive_bayes import GaussionNB, MultinomialNB, BernoulliNB

#使用skl 自带的数据
import sklearn.datasets as datasets
iris = datasets.load_iris()
X = iris['data']
y = iris['target']
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)

#通过画图可知该数据集大致符合正态分布
plt.hist(X[:,0], bin=30)

#使用GaussionNB进行分类
gnb = GaussionNB()
gnb.fit(X_train, y_train)
gnb.score(X_test, y_test)

#使用MultinomialNB分类
mnb = MultinomialNB()
mnb.fit(X_train, y_train)
mnb.score(X_test, y_test)

#使用MultinomialNB分类
bnb = BernoulliNB()
bnb.fit(X_train, y_train)
bnb.score(X_test, y_test)
#因为数据并不符合二分布, 所以使用这种方法分类结果很差
```





## 最大似然估计法

​		根据统计猜测事件参数，然后使用事件参数去验证发生这个统计情况的概率，概率高的则参数准确度高

举例子

比如抛硬币10次得到6次花，那么统计就是 “花：6/10”

此时可以猜测硬币的参数，即抛一次得到花的概率，为0.5，那么计算此参数下发生上述事件的概率为 

![image-20211219171014701](机器学习.assets/image-20211219171014701.png)

此时也可以猜测硬币的参数，为0.6，那么计算此参数下发生上述事件的概率为

<img src="机器学习.assets/image-20211219171045220.png" alt="image-20211219171045220"  />

显然参数为 0.6 的猜测更加靠谱

此时可以得到似然函数为如下，其中 theta 为事件参数

![image-20211219171156684](机器学习.assets/image-20211219171156684.png)

那么可以根据实际发生的事件，计算得到每个参数时对应的概率，如下图

![image-20211219171250079](机器学习.assets/image-20211219171250079.png)

那么这个问题就等同于，求在 theta 等于多少时，似然函数 L(theta) 能够取得最大值

将该问题推广，如果进行多组实验，每组实验同样抛硬币十次，记录下每次实验结果

假设多次的实验结果花面次数分别为 {2,4,4,5,5,6}

那么此时的似然函数如下，也就是该事件发生的概率

（先投了10次，得花面2次，然后投了10次，得花面4次……）
$$
L(\theta)=P(2|\theta)*P(4|\theta)*P(4|\theta)*P(5|\theta)*P(5|\theta)*P(6|\theta)\\
则需要求得使得\ L(\theta)\ 最大的\ \theta\ 值\\
也就是 \theta^{'}=\underset {\theta}{\operatorname {arg\,max} }L(\theta)
$$




## 集成学习

​		多个个体学习器分别进行学习，给出结果，然后使用少数服从多数等策略，得到最终结果，每个个体学习器可以使用不同的结构

![image-20211219194721503](机器学习.assets/image-20211219194721503.png)

集成学习的方式能够有效地提高系统的准确性

![image-20211219194920239](机器学习.assets/image-20211219194920239.png)





#### [AdaBoost](https://zhuanlan.zhihu.com/p/27126737?utm_source=wechat_session&utm_medium=social&utm_oi=1044170377731248128)

​		AdaBoost 使用集成学习的思路，先后训练多个个体学习器，期间根据分类结果不断调整样本权重，最后将多个分类器结果集成起来，达到较高的准确率

1.  初始每个样本权重相同，每个分类器的重要程度相同
2.  训练一个分类器，基于最大正确权重比例的原则，使用阈值一刀切的方法进行分类，将样本分为两类
3.  查看第一个分类器的错误样本，提升这些被分类错误样本的权重
4.  训练第二个分类器，基于最大正确比例的原则，使用阈值一刀切的方法进行分类，将样本分为两类
5.  查看第二个分类器的错误样本，提升这些被分类错误样本的权重
6.  ……循环往复训练多个分类器
7.  将 所有分类器的重要程度 乘 其对某个数据的分类结果给出对该数据的最终分类结果







#### Gridient Boosting

1.  根据样本集训练得到模型1, 将模型1的预测结果与实际的样本数据做差得到残差数据
2.  根据残差数据训练模型2, 将 `模型1+模型2` 的预测结果与残差数据做差得到新的残差数据
3.  不断重复上述两步，使用新的残差数据训练多个模型
4.  最终将多个模型结合到一起



第一次拟合模型

![image-20211221094900316](机器学习.assets/image-20211221094900316.png)

第一次残差数据以及残差数据拟合

![image-20211221094940664](机器学习.assets/image-20211221094940664.png)

将模型1和模型2相加得到新的残差数据

![image-20211221095127106](机器学习.assets/image-20211221095127106.png)

根据再次残差数据训练模型3

![image-20211221095201894](机器学习.assets/image-20211221095201894.png)

最终将所有模型相加作为最终模型

![image-20211221095226575](机器学习.assets/image-20211221095226575.png)















## 自然语言处理

#### sklearn中的词频统计

```python
#导包
from sklearn.feature_extraction.text import CountVectorizer

#创建词频统计器
#可设置参数 stop_words = 'english' , 统计时会自动忽略内置的英语中某些没用的词
cv = CountVectorizer()
#统计词频, 这里的 X 是自然语言文本的数组类型 , 
#返回一个 形状是 a*b的稀松矩阵, 其中a是句子的个数, b是所有句子中非重复单词的个数
#这个返回的稀松矩阵可作为以上分类问题中的样本数据, 然后配合文本的标签就可以训练给文本分类的模型
X_cv = cv.fit_transform(X)
#查看统计结果
print(X_cv)
#该算法将各个单词都映射成一个数字 , 可通过属性查看映射关系
cv.vocabulary_
```

#### sklearn - nlp - 新闻分类案例

```python
#导包
from sklearn.naive_bayes import MultinomialNB, BernoulliNB
import sklearn.datasets as datasets

#新闻数据
#设置参数只要标签和正文部分
data = datasets.fetch_20newsgroups(remove=('headers','footers','quotes'))

#新闻标签
y = data.target
#新闻正文
X = data.data

#文本数据单词量化
from sklearn.feature_extration.text import CountVectorizer,TfidVectorizer

cv = CountVectorizer(stop_words='english')
X2 = cv.fit_transform(X)
X2

#分割数据为训练数据和测试数据
X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.2)

#使用多分类分类器进行训练
mnb = MultinomialNB()
mnb.fit(X_train, y_train)
mnb.score(X_test, y_test)

#使用二分类分类器进行训练, 因为新闻的分类数不是二分类问题, 所以这种方式效果很差
bnb = BernoulliNB()
bnb.fit(X_train, y_train)
bnb.score(X_test, y_test)

#对文本数据进行带权重的量化
tfidf = TfidfVectorizer(stop_words='english')
X3 = tfidf.fit_transform(X)
X3
#分割数据
X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.2)
#使用多分类分类器进行训练 , 结果发现带权重的单词量化分类结果更好
mnb = MultinomialNB()
mnb.fit(X_train, y_train)
mnb.score(X_test, y_test)

#对文本数据进行考虑词组的量化
#ngram_range 指定考虑词组的长度
#因为考虑了词组的划分, 所以这样返回的单词频次矩阵会成倍增大
cv = CountVectorizer(stop_words='english', ngram_range=(1,3))
X4 = cv.fit_transform(X)
X4
```



#### nltk

> 一个独立的专门用来处理自然语言的工具包
>
> pip install nltk
>
> 官网需要翻墙



#### gensim 家的 word2vec

> pip install gensim



#### jieba : 中文处理工具

> pip install jieba
>
> 在处理中文时要注意两个 包含相同单词 但是语序不同 的句子 表达的意思不相同 的情况, 此时如果单纯按照单个单词进行向量化而不考虑词组 , 那么两个意义不同的句子返回的特征矩阵将会是相同的, 所以为了区分意义, 应当在单词向量化时考虑词组.





## SVM

### SVM - 回归问题

#### SVM处理回归问题 - 多项式回归

> 使用sklearn中的 svr 算法

> 线性问题就是求出来的是一条直线
>
> svr 算法求多项式时, 对二次幂方程表现不佳, 对更高次幂表现尚可
>
> 如果数据本身符合多项式的分布, 那么使用多项式算出来的函数能够较好地拟合过去或将来的数据

```python
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
#导包
from sklearn.svm import SCR

#生成训练数据
X = np.linspace(-5,5,30).reshape(-1,1)
y = (X-2)**2 + X*5 + 12
#绘制真实的数据图形
plt.scatter(X,y)

#使用svm进行回归计算
# kernel 设置求得的回归函数的类型, poly是多项式, 即一元多次方程
# degree 设置多项式中最高的次幂
svr = SVR(kernel = 'ploy', degree=2)
svr.fit(X,y)
y_ = svr.predict(X)
#绘制预测的函数图形
plt.plot(X,y_)


#使用数据预处理将原本多次幂方程中一维的 X 数据变为二维数据
#从而可以使得 线性回归算法可以使用预处理后生成的数据对多次幂方程进行回归计算
from sklearn.preprocessing import PolynomialFeatures
#自变量数据转换
# degree 设置将原来的数据进行最高扩展为几次幂
poly = PolynomialFeature(degree = 3)
X_train = poly.fit_transform(X)
X_train.shape
#使用转换后的数据进行训练
lr = LinearRegression()
lr.fit(X_train,y)
#因为现在用于训练的样本集形状已经改变, 所以测试集也要使用相同形状的数据
X_test = poly.fit_transform(np.linspace(-10,10,100).reshape(-1,1))
y_ = lr.predict(X_test)
#此时便实现了使用线性回归解决非线性方程的计算问题
```

#### SVM处理回归问题 - 基于半径回归

> 如果数据能够被基于半径的回归算法拟合, 那么也仅仅是在样本范围内能较好地拟合, 出了样本范围就不能很好地拟合, 参照如下 对 sin 函数的回归

```python
#准备一个sin的数据(非线性)
X = np.linspace(0, 3*np.pi, 50).reshape(-1,1) 
y = np.sin(X)
plt.scatter(X,y)

#分别使用不同的算法对数据进行fit
svr_linear = SVR(kernel='linear')
svr_rbf = SVR(kernel='rbf')
svr_poly = SVR(kernel='poly')
svr_linear.fit(X,y)
svr_rbf.fit(X,y)
svr_poly.fit(X,y)

#准备测试数据
X_test = np.linspace(0, 3*np.pi, 180).reshape(-1,1)

#使用不同的算法进行测试
y1 = svr_linear.predict(X_test)
y2 = svr_rbf.predict(X_test)
y3 = svr_poly.predict(X_test)
#画图比较, 发现高斯分布的rbf算法能够对sin函数进行拟合, 但是超出样本的范围后, 预测函数就放飞自我了
plt.scatter(X,y)
plt.plot(X_test, y1)
plt.plot(X_test, y2)
plt.plot(X_test, y3)
```



### SVM - 分类问题

#### svm处理分类问题 - 线性划分

> svm分类使用 sklearn中的svc算法

> 此类问题中, 二维坐标系中的点可直接使用一条直线进行分类

```python
from sklearn.svm import SVC
import sklearn.datasets as datasets

#在坐标系中 生成一堆随机散布在 指定的中心点周围 的点
#n_sample 指定生成多少个点
#center 设置有几个中心点
#n_features 设置使用的是几维的坐标系, 也就是生成的点是几维的数据
#返回的 X 是样本点, y 是类别标签,y的种类数就是指定的center数
X, y = datasets.make_blobs(n_samples=50, center=2)
X.shape
y

#画图展示样本点
#c 指定点的颜色 , 如果给的是一个数组 , 那么按照数组中的数据的分类情况给点指定不同的颜色
#cmap 指定点颜色的映射值
from matplotlib.colors import ListedColormap
colors = ListedColormap(['r','b'])
plt.scatter(X[:,0], X[:,1], c=y, cmap=colors)

#创建一个svm分类器, 指定分类数据的类型为linear线性的, 默认是高斯分布
svc = SVC(kernel = 'linear')
#分类
svc.fit(X,y)
#获取到计算得出的系数和截距, 因为样本数据X有两个属性, 所以这里系数有两个
w1,w2 = svc.coef_[0]
b, = svc.intercept_
#此时求得的分割线应当为 y=x1*w1 + x2*w2 + b, 将样本点X的数据依次代入这个方程, 得到的y的值就是该点距离这条分割线的距离
#当上面这个方程的 y 等于 0 时, 即 0=x1*w1 + x2*w2 + b, 就是这条分割线
#其中 x1 和 x2 分别是 样本数据X中每一项的 x 的值和 y 的值
#那么就得到了这条直线在当前这个坐标系中的方程 , 即 0=w1*x + w2*y +b , 就是 y = (-w1/w2)*x - b/w2
#根据如上将分割线的斜率和截距求出
w_ = -w1/w2
b_ = -b/w2
#画出这条分割线
x = np.linspace(-2,2,50)
plt.plot(x, x*w_+b_)

#查看支持向量点
support_vectors_ = svc.support_vectors_
#画出支持向量点
plt.scatter(support_vectors_[:,0], support_vectors_[:,1], color='purple', s=300, alpha=0.3)
#画出过支持向量点的线
#就是画出距离分割线距离为 1 和 -1 的线
# 1=w1*x + w2*y +b 和 -1=w1*x + w2*y +b
# 由此可求出两条线各自的截距
b1 = -(b+1) / w2
b2 = -(b-1) / w2
#画线
plt.plot(x, x*w_+b1, ls='--')
plt.plot(x, x*w_+b2, ls='--')
```



#### svm处理分类问题 - 超平面划分 

> 此类问题中,二维坐标系中的点不可使用一条线进行划分, 所以需要将这些点映射到三维空间中, 使用一个平面划分

```python
#生成状态分布的300个二维的点
X = np.random.randn(300,2)
plt.scatter(X[:,0],X[:,1])

#使用点的坐标相乘, 如果大于0那么这个点就在一三象限, 反之则在二四象限
#使用该条件作为绘制图形颜色的分类, 可将点分为两类进行绘制
x = X[:,0]
y = X[:,1]
z = x*y
cond = z>=0
plt.scatter(x,y, c=cond)

#使用svm对点进行象限上的分类, 一三象限为一类, 二四象限为一类
#设置kernel为rbf指定数据分布情况为高斯分布
#样本中的分类数据则为上一步求出来的是否大于0的bool数组
svc = SVC(kernel='rbf')
svc.fit(X, cond)

#生成测试数据
x1 = np.linspace(-3,3,100)
y1 = np.linspace(-3,3,100)
X1, Y1 = np.meshgrid(x1, y1)
X_test = np.concatenate([X1.reshape(-1,1), Y1.reshape(-1,1)], axis=-1)
plt.scatter(X_test[:,0], X_test[:,1])

#使用svm进行分类
y_ = svc.predict(X_test)
plt.scatter(X_test[:,0], X_test[:,1], c=y_)

#查看各个点距离分类超平面的距离
d_ = svc.decision_function(X_test)
d_

#绘制各个点距离分类平面的等高线图
#在图中颜色越深离分离平面越远
plt.contourf(X1, Y1, d_.reshape(100,100))
```



### SVM 人脸识别案例 - 分类问题

```python
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import sklearn.datasets as datasets
from sklearn.svm import SVC

#获取人脸数据的训练集
#min_faces_per_person 设置每个人至少70张图片才列入到训练集中
#返回的是字典类型数据
faces = datasets.fetch_lfw_people(min_faces_per_person=70,resize=1)
faces

#获取样本数据, X就是图片每个像素的数据
X = faces['data']
y = faces['target']
names = faces.target_names
#1k多张人脸图片数据
images = faces['images']
images.shape

#随机查看一张图片
index = np.random.randint(1288,size=1)[0]
plt.imshow(image[index], cmap=plt.cm.gray)
names[y[index]]

#分割数据
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)

#创建svm分类器fit数据
svc = SVC(kernel='rbf')
svc.fit(X_train, y_train)
svc.score(X_test, y_test)

#然后发现效果很差, 因为样本数据中的特征过多, 有1w多个
#使用PCA主成分分析法对样本数据特征进行降维, 降维后的数据能够更好地反映数据的特征
from sklearn.decomposition import PCA
#n_components 设置将特征数据降维至多少维, 也就是保留多少个特征, 也可以设置百分比, 就是保留重要性前xx%的特征
#whiten 设置数据是否归一化, 归一化能对预测结果准确率有很大的提升
pca = PCA(n_components=0.9, whiten=True)
X_pca = pca.fit_transform(X)
#此时发现返回的结果数据中只保留了设置的特征数
X_pca.shape

#使用pca处理后的数据进行训练, 然后发现准确率大大提升
X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)
svc = SVC(kernel='rbf')
svc.fit(X_train, y_train)
svc.score(X_test, y_test)

y
#此时输出 y 发现训练样本中包含7个人 , 也就是将样本分为 7 类, 但是这七类的样本数据数量并不均衡, 这可能会影响模型的准确率 
#使用 imblearn 下的对样本均衡化
#需要 pip install imblearn
#如果下载之后无法使用, 可以手动下载这个包然后复制到 Anaconda > Lib > site-packages 中
from imblearn.over_sampling import SMOTE
#将原数据过采样, 也就是增加数据使其各个分类的样本数据平衡
X2, y2 = smote.fit_resample(X,y)
#使用均衡后的样本进行fit ,发现准确率又会有所提升
pca = PCA(n_components=0.9, whiten=True)
X2_pca = pca.fit_transform(X2)
#因为降维后的数据没法画图, 所以这里将原图数据也切分保留
face_train, face_test, X_train, X_test, y_train, y_test = 
	train_test_split(X2, X2_pca, y2, test_size=0.2)
svc = SVC(kernel='rbf')
svc.fit(X_train, y_train)
svc.score(X_test, y_test)
#预测的结果数据
y_ = svc.predict(X_test)
#将测试数据前100张原图画出来, 其中模糊的图片就是过采样造出来的数据
for i in range(100):
    ax = plt.subplot(10,10,i+1)
    face = face_test[i].reshape(127,94) #一维数据无法画图, 需要转换
    ax.imshow(face, cmap='gray')
    ax.axis('off')
    t = names[y_test[i]] #真实值
    p = names[y_[i]] #预测值
    ax.set_title('True: %s\nPredict: %s' % (t,p)) #对比真实值和预测值
```



## [特征工程](https://www.cnblogs.com/jasonfreak/p/5448385.html)

### 数据降维

#### PCA -- 数据降维

>   主成分分析, 用于对数据降维

1.  假设有一批二维数据

    ![image-20211221164349561](机器学习.assets/image-20211221164349561.png)

2.  求所有数据点的均值点

    ![image-20211221164407439](机器学习.assets/image-20211221164407439.png)

3.  将原点移动到均值点 （数据值-均值）

    ![image-20211221164451021](机器学习.assets/image-20211221164451021.png)

4.  确定一条过原点的直线，使得所有点到该直线的投影之和最大

    这里可以利用勾股定理，其中原点到数据点的距离总是不变，投影是c边，那么这意味着要求的问题就是最大化c的和，或者最小化b的和

    ![image-20211221165929567](机器学习.assets/image-20211221165929567.png)

5.  得到目标直线，该直线为PC1轴

    ![image-20211221170024987](机器学习.assets/image-20211221170024987.png)

6.  在与主轴垂直的面上找到一条直线，同样使得数据点的映射和最大，因为这里是二维，垂直于主轴的仅仅是一条线，那么直接取该线作为PC2即可

7.  使用主轴对数据进行映射，得到降维后的数据

    （对于高维数据，比如三维，需要在PC1和PC2组成的面上对数据进行映射

    依次类推，如果是四维，那么需要确定三条直线PC1,PC2和PC3,并以此进行数据映射）

    ![image-20211221170528838](机器学习.assets/image-20211221170528838.png)

```python
import numpy as np
import sklearn.datasets as datasets
from sklearn.decomposition import PCA

iris = datasets.load_iris()
X = iris['data']
y = iris['target']

#PCA降维
pca = PCA(n_components=0.95,whiten=False)
X_pca = pca.fit_transform(X)
X_pca

#PCA的计算原理
#1. 去中心化 , 就是每个元素都减去其所在列的平均值
A = X - X.mean(axis=0)
#2. 求协方差
V = np.cov(A, rowvar = False)
#3. 特征值和特征向量
T,Tv = np.linalg.eig(V)
#4. 选取大于95%的特征值所对应的的特征向量
cond = (T.cumsum()/T.sum()) > 0.95
P = Tv.loc[:, cond]
#5. 使用选取出来的特征向量和原始数据进行矩阵运算 , 这个结果就是上面pca求出来的结果
X.dot(P)
```





### 特征筛选

> 去除原数据中 方差较小的特征属性

```python
#导包
from sklearn.feature_selection import VarianceThreshold
import sklearn.datasets as datasets

iris = datasets.load_iris()
X = iris['data']
X
X.var()
#特征方差筛选器, 经过方差筛选, 部分特征属性会被筛选去除, 留下特征的方差大于指定的值
v = VarianceThreshold(3)
X2 = v.fit_transform(X)
X2
X2.var()
```





## 参数交叉验证

> 在使用以上 sklearn 中的机器学习算法时, 很多时候需要通过多次对多个参数进行调整来获取更好的训练结果
>
> 这个过程就很繁琐且无聊
>
> 使用 GridSearchCV 方法可以一次性交叉尝试很多参数组合然后一次性返回所有参数下的训练结果

```python
#导包
from sklearn.model_selection import GridSearchCV

#以 svc 为例使用 GridSearchCV, 其中C和tol是SVC中的可调参数
C = [1,2,3]
tol = [1e-4, 1e-3, 1e-2]
svc = SVC()
clf = GridSearchCV(svc, param_grid={'C': C, 'tol':tol})
clf.fit(X_train, y_train)
#查看得分最高的参数组合, 此时直接使用 clf 进行预测使用的就是最佳参数的 SVC
clf.best_params_
clf.score(X_test, y_test)
#获取得分最高的 SVC 实例
clf.best_estimator_
```







## 附录

#### 回归问题

回归问题的本质是使用函数来拟合数据和结果之间的对应关系

衡量一个函数模型的好坏有两个标准 :  bias 和 various 

* bias 指该模型预测的结果整体与真实值之间的差异, 如果模型过于简单, 此时会造成 bias 过大, 也就是完全不能反映数据集的分布特点, 称之为欠拟合
* various 指该模型的各个预测点之间的差异, 如果模型过于复杂, 此时函数图像会跌宕起伏, 微小的自变量变化也会引起结果的剧烈变化, 且此时对测试集表现出极大的偏差, 称之为过拟合

解决欠拟合和过拟合?

欠拟合 : 适当增加参数的个数, 或者提高函数的复杂性,即增大函数的最大次幂

过拟合 : 使用更大的训练数据集能够很好的约束该复杂模型, 如果受限于训练数据集, 那么也可以尝试添加正则化参数, 正则化项会减缓原函数的跌宕起伏



#### 分类问题

分类问题的本质是根据 gaussion distribution ( 正态分布 ) 来算测试数据为某一类的可能性,  然后根据概率公式求出可能为该类的概率

步骤:

1. 使用给定的训练数据集, 每一个分类下有一批数据, 根据这批数据求出该分类的 gaussion distribution 函数, 也即是函数图像上的一个圆
2. 然后使用该 gaussion distribution 函数计算测试数据
3. 离圆心越近的为该分类的概率越大
4. 使用概率公式求出该分类的概率

